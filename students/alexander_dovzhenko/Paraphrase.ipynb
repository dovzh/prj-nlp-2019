{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paraphrase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read test and train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_tags(string):\n",
    "    return [tuple(i.split(\"/\")) for i in string.split()]\n",
    "\n",
    "def readTrainData(filename):\n",
    "    data = []\n",
    "    for line in open(filename):\n",
    "        line = line.strip()\n",
    "        #read in training or dev data with labels\n",
    "        if len(line.split('\\t')) == 7:\n",
    "            (trendid, trendname, origsent, candsent, judge, origsenttag, candsenttag) = \\\n",
    "            line.split('\\t')\n",
    "        else:\n",
    "            continue\n",
    "        # ignoring the training data that has middle label \n",
    "        nYes = eval(judge)[0]            \n",
    "        if nYes >= 3:\n",
    "            amt_label = True\n",
    "            data.append((split_tags(origsenttag), split_tags(candsenttag), amt_label))\n",
    "        elif nYes <= 1:\n",
    "            amt_label = False\n",
    "            data.append((split_tags(origsenttag), split_tags(candsenttag), amt_label))\n",
    "    return data\n",
    "\n",
    "def readTestData(filename):\n",
    "    data = []\n",
    "    for line in open(filename):\n",
    "        line = line.strip()\n",
    "        #read in training or dev data with labels\n",
    "        if len(line.split('\\t')) == 7:\n",
    "            (trendid, trendname, origsent, candsent, judge, origsenttag, candsenttag) = \\\n",
    "            line.split('\\t')\n",
    "        else:\n",
    "            continue\n",
    "        # ignoring the training data that has middle label \n",
    "        nYes = int(judge[0])\n",
    "        if nYes >= 4:\n",
    "            expert_label = True\n",
    "        elif nYes <= 2:\n",
    "            expert_label = False\n",
    "        else:\n",
    "            expert_label = None\n",
    "        data.append((split_tags(origsenttag), split_tags(candsenttag), expert_label))\n",
    "    return data\n",
    "\n",
    "train_data = readTrainData(\"SemEval-PIT2015-py3/data/train.data\")\n",
    "dev_data = readTrainData(\"SemEval-PIT2015-py3/data/dev.data\")\n",
    "test_data = readTestData(\"SemEval-PIT2015-py3/data/test.data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyemd import emd\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "word2vec_model = KeyedVectors.load_word2vec_format(\"numberbatch-en.txt\", binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "lem = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(words):\n",
    "    words = [w for w in words if w not in stop_words]\n",
    "    words = [w for w in words if len(w) > 3]\n",
    "    words = [lem.lemmatize(w) for w in words]\n",
    "    return words\n",
    "\n",
    "def sample_x(sample, sub=False):\n",
    "    get_words = lambda ann_tw: [ann_w[0] for ann_w in ann_tw]\n",
    "    to_vec = lambda w : word2vec_model[w] if w in word2vec_model else np.zeros(300)\n",
    "    \n",
    "    def tw_vec(vecs):\n",
    "        if not vecs:\n",
    "            return np.zeros(300)\n",
    "        return np.sum(np.array(vecs), axis=0) / len(vecs)\n",
    "    \n",
    "    text0 = preprocess_text(get_words(sample[0]))\n",
    "    text1 = preprocess_text(get_words(sample[1]))\n",
    "\n",
    "    vec0 = tw_vec([to_vec(w) for w in text0])\n",
    "    vec1 = tw_vec([to_vec(w) for w in text1])\n",
    "    #dist = model.wmdistance(get_words(sample[0]), get_words(sample[1]))\n",
    "    #dist = min(dist, 100)\n",
    "\n",
    "    if sub:\n",
    "        return vec0 - vec1\n",
    "    else:\n",
    "        return np.concatenate((vec0, vec1), axis=None)\n",
    "\n",
    "    #return np.concatenate((vec0, vec0), axis=None)\n",
    "    #return {'vecs0': vecs0, 'vecs1': vecs1}\n",
    "\n",
    "def sample_y(sample):\n",
    "    return sample[2]\n",
    "\n",
    "X_train = [sample_x(sample) for sample in train_data]\n",
    "Y_train = [sample_y(sample) for sample in train_data]\n",
    "\n",
    "X_dev = [sample_x(sample) for sample in dev_data]\n",
    "Y_dev = [sample_y(sample) for sample in dev_data]\n",
    "\n",
    "X_test = [sample_x(sample) for sample in test_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.93      0.65      0.76      3862\n",
      "        True       0.07      0.36      0.12       280\n",
      "\n",
      "   micro avg       0.63      0.63      0.63      4142\n",
      "   macro avg       0.50      0.51      0.44      4142\n",
      "weighted avg       0.87      0.63      0.72      4142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "lrc = LogisticRegression(random_state=42, solver=\"sag\", max_iter=1000)\n",
    "lrc.fit(X_train, Y_train)\n",
    "print(classification_report(lrc.predict(X_dev), Y_dev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OutputPredictions(Y_pred, outfile):\n",
    "    # output the results into a file\n",
    "    outf = open(outfile,'w') \n",
    "\n",
    "    for y in Y_pred:\n",
    "        if y >= 0.5:\n",
    "            outf.write(\"true\\t\" + \"{0:.4f}\".format(y) + \"\\n\")\n",
    "        else:\n",
    "            outf.write(\"false\\t\" + \"{0:.4f}\".format(y) + \"\\n\")\n",
    "\n",
    "    outf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sasha/Documents/prj-nlp-2019_/practice_11\n"
     ]
    }
   ],
   "source": [
    "%cd -\n",
    "\n",
    "#Y_pred = [1] * len(test_data)\n",
    "Y_pred = lrc.predict(X_test)\n",
    "OutputPredictions(Y_pred, 'SemEval-PIT2015-py3/systemoutputs/PIT2015_SASHA_01_LG.output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sasha/Documents/prj-nlp-2019_/practice_11/SemEval-PIT2015-py3/scripts\n",
      "838\tBASELINE\t02_LG\t\tF: 0.589\tPrec: 0.679\tRec: 0.520\t\tP-corr: 0.511\tF1: 0.601\tPrec: 0.674\tRec: 0.543\n",
      "838\tSASHA\t01_LG\t\tF: 0.082\tPrec: 0.400\tRec: 0.046\t\tP-corr: 0.089\tF1: 0.379\tPrec: 0.253\tRec: 0.760\n"
     ]
    }
   ],
   "source": [
    "%cd SemEval-PIT2015-py3/scripts\n",
    "!python3 pit2015_eval_single.py ../data/test.label ../systemoutputs/PIT2015_BASELINE_02_LG.output\n",
    "!python3 pit2015_eval_single.py ../data/test.label ../systemoutputs/PIT2015_SASHA_01_LG.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
